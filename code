import zipfile
from tensorflow.keras.preprocessing.image import ImageDataGenerator #type: ignore
from tensorflow.keras.models import Sequential #type: ignore
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout #type: ignore

# Unzipping the dataset
zip_path = 'archive.zip'  # Path to your zip file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall('brain_tumor_dataset')

# Directory paths
train_dir = 'brain_tumor_dataset/training'
test_dir = 'brain_tumor_dataset/testing'

# Data Augmentation and Preprocessing
datagen = ImageDataGenerator(rescale = 1./255, validation_split = 0.2)

train_generator = datagen.flow_from_directory(
    train_dir,
    target_size = (150, 150),
    batch_size = 32,
    class_mode = 'categorical',
    subset = 'training'
)

validation_generator = datagen.flow_from_directory(
    train_dir,
    target_size = (150, 150),
    batch_size = 32,
    class_mode = 'categorical',
    subset = 'validation'
)


# Building the CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)),
    MaxPooling2D((2, 2)),
    
    Conv2D(64, (3, 3), activation = 'relu'),
    MaxPooling2D((2, 2)),
    
    Conv2D(128, (3, 3), activation = 'relu'),
    MaxPooling2D((2, 2)),
    
    Flatten(),
    Dense(128, activation = 'relu'),
    Dropout(0.5),
    Dense(4, activation = 'softmax')  # 4 classes: glioma, meningioma, notumor, pituitary
])

  
# Compiling the model
model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

  
# Training the model
history = model.fit(
    train_generator,
    steps_per_epoch = train_generator.samples // train_generator.batch_size,
    epochs = 10,
    validation_data = validation_generator,
    validation_steps = validation_generator.samples // validation_generator.batch_size
)

  
# Save the model in the native Keras format
model.save('brain_tumor_detector.keras')
